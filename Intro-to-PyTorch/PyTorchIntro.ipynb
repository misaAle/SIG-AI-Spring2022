{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa669550",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0250414e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3600, -0.2903, -0.5248],\n",
       "        [-0.1541, -0.4697,  0.1765],\n",
       "        [-0.2172, -0.4495,  0.6826],\n",
       "        [ 0.4822,  0.6903, -0.4127],\n",
       "        [ 0.8972, -0.8654,  0.2672]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(5, 3).uniform_(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1962ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (3,4)\n",
    "rand_tensor = torch.rand(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7c8f2f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9688, 0.6981, 0.9489, 0.7595],\n",
       "        [0.8256, 0.1407, 0.7666, 0.1109],\n",
       "        [0.2756, 0.1802, 0.8921, 0.7898]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2675e2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rand_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1781b726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy np_array value: \n",
      " [[0.9687947  0.69807833 0.94892    0.75952375]\n",
      " [0.8256072  0.14070284 0.7665622  0.11088091]\n",
      " [0.27562755 0.18015355 0.89205724 0.7898049 ]] \n",
      "\n",
      "Tensor x_np value: \n",
      " tensor([[0.9688, 0.6981, 0.9489, 0.7595],\n",
      "        [0.8256, 0.1407, 0.7666, 0.1109],\n",
      "        [0.2756, 0.1802, 0.8921, 0.7898]]) \n",
      "\n",
      "Numpy np_array after * 2 operation: \n",
      " [[1.9375894  1.3961567  1.89784    1.5190475 ]\n",
      " [1.6512144  0.2814057  1.5331244  0.22176182]\n",
      " [0.5512551  0.3603071  1.7841145  1.5796098 ]] \n",
      "\n",
      "Tensor x_np value after modifying numpy array: \n",
      " tensor([[1.9376, 1.3962, 1.8978, 1.5190],\n",
      "        [1.6512, 0.2814, 1.5331, 0.2218],\n",
      "        [0.5513, 0.3603, 1.7841, 1.5796]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "print(f\"Numpy np_array value: \\n {np_array} \\n\")\n",
    "print(f\"Tensor x_np value: \\n {x_np} \\n\")\n",
    "\n",
    "np.multiply(np_array, 2, out=np_array)\n",
    "\n",
    "print(f\"Numpy np_array after * 2 operation: \\n {np_array} \\n\")\n",
    "print(f\"Tensor x_np value after modifying numpy array: \\n {x_np} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8930357e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([4, 5])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(4, 5)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "492871b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  tensor = tensor.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43fb5b34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5131, 0.9625, 0.3754, 0.0408],\n",
      "        [0.2458, 0.7542, 0.3710, 0.9192],\n",
      "        [0.0195, 0.4349, 0.1687, 0.5693],\n",
      "        [0.4643, 0.7828, 0.5637, 0.0317]])\n",
      "First row:  tensor([0.5131, 0.9625, 0.3754, 0.0408])\n",
      "First column:  tensor([0.5131, 0.2458, 0.0195, 0.4643])\n",
      "Last column: tensor([0.0408, 0.9192, 0.5693, 0.0317])\n",
      "tensor([[0.5131, 0.0000, 0.3754, 0.0408],\n",
      "        [0.2458, 0.0000, 0.3710, 0.9192],\n",
      "        [0.0195, 0.0000, 0.1687, 0.5693],\n",
      "        [0.4643, 0.0000, 0.5637, 0.0317]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(4, 4)\n",
    "print(tensor)\n",
    "print('First row: ',tensor[0])\n",
    "print('First column: ', tensor[:, 0])\n",
    "print('Last column:', tensor[:, -1])\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7866d7a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.5131, 2.0000, 2.3754, 2.0408],\n",
      "        [2.2458, 2.0000, 2.3710, 2.9192],\n",
      "        [2.0195, 2.0000, 2.1687, 2.5693],\n",
      "        [2.4643, 2.0000, 2.5637, 2.0317]])\n",
      "tensor([[0.5131, 0.0000, 0.3754, 0.0408],\n",
      "        [0.2458, 0.0000, 0.3710, 0.9192],\n",
      "        [0.0195, 0.0000, 0.1687, 0.5693],\n",
      "        [0.4643, 0.0000, 0.5637, 0.0317]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor + 2)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5fe6704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4059, 0.3029, 0.0966, 0.4512],\n",
      "        [0.3029, 1.0429, 0.5906, 0.3524],\n",
      "        [0.0966, 0.5906, 0.3529, 0.1222],\n",
      "        [0.4512, 0.3524, 0.1222, 0.5343]])\n",
      "tensor([[0.4059, 0.3029, 0.0966, 0.4512],\n",
      "        [0.3029, 1.0429, 0.5906, 0.3524],\n",
      "        [0.0966, 0.5906, 0.3529, 0.1222],\n",
      "        [0.4512, 0.3524, 0.1222, 0.5343]])\n"
     ]
    }
   ],
   "source": [
    "x1 = tensor @ tensor.T\n",
    "print(x1)\n",
    "x2 = tensor.matmul(tensor.T)\n",
    "print(x2)\n",
    "# x3 = torch.matmul(tensor, tensor.T, out=y3)\n",
    "# print(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f106f0de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5131, 0.0000, 0.3754, 0.0408],\n",
      "        [0.2458, 0.0000, 0.3710, 0.9192],\n",
      "        [0.0195, 0.0000, 0.1687, 0.5693],\n",
      "        [0.4643, 0.0000, 0.5637, 0.0317]]) \n",
      "\n",
      "tensor([[5.5131, 5.0000, 5.3754, 5.0408],\n",
      "        [5.2458, 5.0000, 5.3710, 5.9192],\n",
      "        [5.0195, 5.0000, 5.1687, 5.5693],\n",
      "        [5.4643, 5.0000, 5.5637, 5.0317]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cac2cb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3de2ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ae1e54a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1145039d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = training_data[13]\n",
    "plt.title(label)\n",
    "plt.imshow(img.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da6456fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ac2afa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1dde57a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92886994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b523f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a194c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "147cb4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ebe92d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X) \n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5e60b563",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7bddcfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5b110d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):        \n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1e0142ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "12eb4058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.307780  [    0/60000]\n",
      "loss: 2.296177  [ 6400/60000]\n",
      "loss: 2.289568  [12800/60000]\n",
      "loss: 2.286807  [19200/60000]\n",
      "loss: 2.282157  [25600/60000]\n",
      "loss: 2.279558  [32000/60000]\n",
      "loss: 2.279210  [38400/60000]\n",
      "loss: 2.259496  [44800/60000]\n",
      "loss: 2.244260  [51200/60000]\n",
      "loss: 2.248813  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 25.5%, Avg loss: 0.035200 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.234715  [    0/60000]\n",
      "loss: 2.249301  [ 6400/60000]\n",
      "loss: 2.234448  [12800/60000]\n",
      "loss: 2.226330  [19200/60000]\n",
      "loss: 2.230519  [25600/60000]\n",
      "loss: 2.201558  [32000/60000]\n",
      "loss: 2.234405  [38400/60000]\n",
      "loss: 2.178332  [44800/60000]\n",
      "loss: 2.095504  [51200/60000]\n",
      "loss: 2.128554  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 36.3%, Avg loss: 0.033697 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.186488  [    0/60000]\n",
      "loss: 2.223050  [ 6400/60000]\n",
      "loss: 2.132253  [12800/60000]\n",
      "loss: 2.083698  [19200/60000]\n",
      "loss: 2.124041  [25600/60000]\n",
      "loss: 2.112988  [32000/60000]\n",
      "loss: 2.048742  [38400/60000]\n",
      "loss: 2.005967  [44800/60000]\n",
      "loss: 2.102164  [51200/60000]\n",
      "loss: 1.945131  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 44.9%, Avg loss: 0.031260 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.989059  [    0/60000]\n",
      "loss: 1.954768  [ 6400/60000]\n",
      "loss: 2.001384  [12800/60000]\n",
      "loss: 1.975285  [19200/60000]\n",
      "loss: 1.915704  [25600/60000]\n",
      "loss: 1.935364  [32000/60000]\n",
      "loss: 1.740301  [38400/60000]\n",
      "loss: 1.820746  [44800/60000]\n",
      "loss: 1.818821  [51200/60000]\n",
      "loss: 1.732595  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 49.6%, Avg loss: 0.028402 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.812974  [    0/60000]\n",
      "loss: 1.729074  [ 6400/60000]\n",
      "loss: 1.792364  [12800/60000]\n",
      "loss: 1.633432  [19200/60000]\n",
      "loss: 1.637642  [25600/60000]\n",
      "loss: 1.661943  [32000/60000]\n",
      "loss: 1.875554  [38400/60000]\n",
      "loss: 1.713694  [44800/60000]\n",
      "loss: 1.747519  [51200/60000]\n",
      "loss: 1.604700  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 51.1%, Avg loss: 0.025886 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.639506  [    0/60000]\n",
      "loss: 1.658006  [ 6400/60000]\n",
      "loss: 1.397698  [12800/60000]\n",
      "loss: 1.598732  [19200/60000]\n",
      "loss: 1.612797  [25600/60000]\n",
      "loss: 1.389281  [32000/60000]\n",
      "loss: 1.577486  [38400/60000]\n",
      "loss: 1.439330  [44800/60000]\n",
      "loss: 1.489915  [51200/60000]\n",
      "loss: 1.537516  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 53.2%, Avg loss: 0.024027 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.476706  [    0/60000]\n",
      "loss: 1.381817  [ 6400/60000]\n",
      "loss: 1.325592  [12800/60000]\n",
      "loss: 1.344450  [19200/60000]\n",
      "loss: 1.484245  [25600/60000]\n",
      "loss: 1.216358  [32000/60000]\n",
      "loss: 1.573962  [38400/60000]\n",
      "loss: 1.391698  [44800/60000]\n",
      "loss: 1.442545  [51200/60000]\n",
      "loss: 1.750608  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 54.4%, Avg loss: 0.022633 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.415026  [    0/60000]\n",
      "loss: 1.454328  [ 6400/60000]\n",
      "loss: 1.448358  [12800/60000]\n",
      "loss: 1.478401  [19200/60000]\n",
      "loss: 1.131446  [25600/60000]\n",
      "loss: 1.381579  [32000/60000]\n",
      "loss: 1.448119  [38400/60000]\n",
      "loss: 1.486687  [44800/60000]\n",
      "loss: 1.439040  [51200/60000]\n",
      "loss: 1.326505  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 55.5%, Avg loss: 0.021611 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.495343  [    0/60000]\n",
      "loss: 1.269345  [ 6400/60000]\n",
      "loss: 1.537074  [12800/60000]\n",
      "loss: 1.310315  [19200/60000]\n",
      "loss: 1.402566  [25600/60000]\n",
      "loss: 1.284580  [32000/60000]\n",
      "loss: 1.359607  [38400/60000]\n",
      "loss: 1.218604  [44800/60000]\n",
      "loss: 1.412585  [51200/60000]\n",
      "loss: 1.206776  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.0%, Avg loss: 0.020782 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.244257  [    0/60000]\n",
      "loss: 1.298320  [ 6400/60000]\n",
      "loss: 1.417878  [12800/60000]\n",
      "loss: 1.079536  [19200/60000]\n",
      "loss: 1.168201  [25600/60000]\n",
      "loss: 1.069023  [32000/60000]\n",
      "loss: 1.201829  [38400/60000]\n",
      "loss: 1.436940  [44800/60000]\n",
      "loss: 1.191460  [51200/60000]\n",
      "loss: 1.188705  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.3%, Avg loss: 0.020121 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate=1e-3\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "95b11952",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"data/model.pth\")\n",
    "\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "acef07ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load('data/model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "00b14408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Trouser\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "x, y = test_data[3][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
